{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We are interested into determining the true position $p$ and velocity $v$ of a vehicle at time $t$ based on meausurements that are subject to random error. The observations are taken over fixed time interval; let $\\Delta t$ denote difference between each pair of successive times of measurements. This model can be useful for various tasks such as determining the exact location and velocity at time $t$ and predicting their values at time $t+1$.\n",
    "\n",
    "We assume the following model about the \"true\" posistion and velocity: \n",
    "$$\n",
    "\\left[\\begin{array}{c}p_{t}\\\\v_{t}\\end{array}\\right] = \\left[\\begin{array}{cc}1 & \\Delta t\\\\0 &1\\end{array}\\right]\\left[\\begin{array}{c}p_{t-\\Delta t}\\\\v_{t-\\Delta t}\\end{array}\\right] + \\left[\\begin{array}{c}\\frac{1}{2}b \\Delta t^2\\\\b\\Delta t\\end{array}\\right]+\\epsilon_t,\n",
    "$$\n",
    "where $b$ is a parameter reflecting acceleration, $\\epsilon_t\\sim N(0,Q)$ with $Q$ taken to be diagonal for simplicity.\n",
    "\n",
    "Denoting $z=\\left[\\begin{array}{c}p_{t}\\\\v_{t}\\end{array}\\right]$, $A=\\left[\\begin{array}{cc}1 & \\Delta t\\\\0 &1\\end{array}\\right]$ and $B=\\left[\\begin{array}{c}\\frac{1}{2}b \\Delta t^2\\\\b\\Delta t\\end{array}\\right]$ and $u_t=1$, we can write the model for the hidden markov process as\n",
    "\n",
    "$$\n",
    "z_t = A z_{t-\\Delta t} + B u_t +\\epsilon_t\n",
    "$$\n",
    "\n",
    "Finally model for the noisy measurements $x$ of position and velocity is assumed to be\n",
    "\n",
    "$$\n",
    "x_t = z_t + \\delta_t \n",
    "$$\n",
    "where $\\delta_t \\sim N(0,R)$. For the notation in the slides this implies $C=I_2$, $D=0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for the Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_observations = np.array([4000, 4260, 4550, 4860, 5110])\n",
    "v_observations = np.array([280, 282, 285, 286, 290])\n",
    "\n",
    "x= np.c_[p_observations, v_observations]\n",
    "[n,d] = x.shape\n",
    "\n",
    "Dt = 1  # Difference in time\n",
    "b = 2  # Acceleration\n",
    "\n",
    "# Process / Estimation Errors\n",
    "sigma_p = 20\n",
    "sigma_v = 5\n",
    "\n",
    "# Observation Errors - Uncertainty in the measurement  \n",
    "omega_p = 25  #\n",
    "omega_v = 6\n",
    "\n",
    "#Kalman Filter Matrices needed for the recursions\n",
    "A = np.array([[1, Dt],\n",
    "                  [0, 1]])\n",
    "B = np.array([0.5 * b* Dt ** 2, b*Dt])\n",
    "u = 1\n",
    "C = np.eye(d)\n",
    "D = np.array([0,0])\n",
    "Q = np.diag([sigma_p**2,sigma_v**2])\n",
    "R = np.diag([omega_p**2,omega_v**2])\n",
    "#z_prime = A.dot(X) + B.dot(u)\n",
    "\n",
    "# Initial Conditions\n",
    "\n",
    "v0 = 278\n",
    "z0 = 3995\n",
    "mu0 = np.array([z0,v0])\n",
    "Sigma0 = Q\n",
    "\n",
    "#Objects to store predictions and filtering locations\n",
    "Mu = np.zeros((n,d))\n",
    "Mupred = np.zeros((n,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = mu0\n",
    "Sigma = Sigma0\n",
    "logL = 0\n",
    "\n",
    "for i in range(n):\n",
    "    #observation for time i\n",
    "    x = np.array([p_observations[i],v_observations[i]])\n",
    "\n",
    "    #Prediction\n",
    "    mu = A.dot(mu) + B.T.dot(u)\n",
    "    Sigma  = A.dot(Sigma).dot(A.T)+Q\n",
    "    Mupred[i,:] = mu\n",
    "    \n",
    "    #Kalman Gain\n",
    "    S = C.dot(Sigma).dot(C.T) + R\n",
    "    K = Sigma.dot(C).dot(inv(S))\n",
    "\n",
    "    #Calculate log likelihood based on the i-th measurement\n",
    "    M = C.dot(mu.T) +D.T.dot(u) \n",
    "    logL = logL + multivariate_normal.logpdf(x, mean=M, cov=S)\n",
    "    \n",
    "    # Correction\n",
    "    mu = mu + K.dot(x- C.dot(mu)- D*u )\n",
    "    Sigma = (np.identity(d) - K.dot(C)).dot(Sigma)\n",
    "    Mu[i,:] = mu    \n",
    "    \n",
    "print(\"Kalman Filter log likelihood:\\n\", logL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=range(n)\n",
    "plt.plot(t,p_observations,'o',label='observed')\n",
    "plt.plot(t,Mupred[:,0],'o',label='predicted')\n",
    "plt.plot(t,Mu[:,0],'o',label='filtered')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate $50$ points from the following model \n",
    "$$\n",
    "z_t=0.8 z_{t-1}+0.5+\\epsilon_t,\\;\\;\\;\\;\\epsilon_t\\sim N(0,1),\n",
    "$$\n",
    "$$\n",
    "x_t= z_t+\\delta_t,\\;\\;\\;\\;\\delta_t\\sim N(0,0.5^2),\n",
    "$$\n",
    "where $t=0,1,\\dots,50$ and $z_0=0$.\n",
    "Run the Kalman filter on the simulated data and plot the predicted and filtered paths overlaid on the observed data as well as the 'true' $z$ values, i.e. the values you simulated above.\n",
    "\n",
    "Put your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bob Alice Example of Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ('Rainy', 'Sunny')\n",
    "observations = ('walk', 'shop', 'clean')\n",
    "pi = np.array([0.6, 0.4])  #initial probability \n",
    "A = np.array([[0.7, 0.3],[0.4, 0.6]]) #Transmission probability \n",
    "B = np.array([[0.1, 0.4, 0.5],[0.6, 0.3, 0.1]]) #Emission probability\n",
    "bob_says = np.array([0, 2, 1, 1, 2, 0, 1,2,1,0,0,2,1])\n",
    "print(bob_says)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs_seq, pi, A, B):\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    alpha = np.zeros((T, N))\n",
    "    alpha[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        alpha[t] = np.inner(alpha[t-1],A) * B[:, obs_seq[t]]\n",
    "    return alpha\n",
    "\n",
    "def likelihood(alpha):\n",
    "    # returns log P(Y  \\mid  model)\n",
    "    # using the forward part of the forward-backward algorithm\n",
    "    return  alpha[-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = forward(bob_says, pi, A, B)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Backward Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(obs_seq, A, B):\n",
    "    N = A.shape[0]\n",
    "    T = len(obs_seq)\n",
    "\n",
    "    beta = np.zeros((N,T))\n",
    "    beta[:,-1:] = 1\n",
    "\n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "            beta[n,t] = np.sum(beta[:,t+1] * A[n,:] * B[:, obs_seq[t+1]])\n",
    "\n",
    "    return beta\n",
    "\n",
    "def fb(alpha, beta):\n",
    "    obs_prob = likelihood(alpha)\n",
    "    return (np.multiply(alpha,beta.T) / obs_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=backward(bob_says, A, B)\n",
    "gamma=fb(alpha, beta)\n",
    "print('beta',beta.T)\n",
    "print('gamma',gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs_seq,pi, A, B):\n",
    "    # returns the most likely state sequence given observed sequence x\n",
    "    # using the Viterbi algorithm\n",
    "    T = len(obs_seq)\n",
    "    N = A.shape[0]\n",
    "    delta = np.zeros((T, N))\n",
    "    psi = np.zeros((T, N))\n",
    "    delta[0] = pi*B[:,obs_seq[0]]\n",
    "    for t in range(1, T):\n",
    "        for j in range(N):\n",
    "            delta[t,j] = np.max(delta[t-1]*A[:,j]) * B[j, obs_seq[t]]\n",
    "            psi[t,j] = np.argmax(delta[t-1]*A[:,j])\n",
    "\n",
    "    # backtrack\n",
    "    states = np.zeros(T, dtype=np.int32)\n",
    "    states[T-1] = np.argmax(delta[T-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        states[t] = psi[t+1, states[t+1]]\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_infers=viterbi(bob_says, pi, A, B)\n",
    "names = ['Bob says','Alice infers']\n",
    "BS = list(map(lambda y: observations[y], bob_says))\n",
    "AI = list(map(lambda s: states[s], alice_infers))\n",
    "\n",
    "best_path = pd.DataFrame(np.column_stack([BS,AI]),columns=names)\n",
    "best_path\n",
    "#print(\"Bob says:\", \", \",list(map(lambda y: observations[y], bob_says)))\n",
    "#print(\"Alice infers:\", \", \", list(map(lambda s: states[s], alice_infers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
